ğŸ“š StoryTeller AI â€” Fine-Tuning GPT-2 with LoRA

This project shows how to fine-tune a GPT-2 model with LoRA adapters to create a lightweight storytelling agent.
It uses the TinyStories dataset for short story style and runs easily in Google Colab or on your local machine.

ğŸš€ Features

âœ… Fine-tune GPT-2 using LoRA (memory-efficient)

âœ… Use TinyStories dataset for simple narrative style

âœ… Save & reuse LoRA weights locally

âœ… Easy to run inference with Gradio or Python script

âœ… Perfect for creating a personalized StoryTeller chatbot




ğŸ“¦ Requirements


Python 3.10+


Packages:


transformers

datasets

peft

accelerate

bitsandbytes

gradio (for frontend, optional)


ğŸ† Credits

Dataset: TinyStories

Fine-Tuning: LoRA

Language Model: GPT-2





![Screenshot (840)](https://github.com/user-attachments/assets/908fa860-4982-42c6-9ad5-de6b52bb9f4e)


