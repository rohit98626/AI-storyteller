📚 StoryTeller AI — Fine-Tuning GPT-2 with LoRA

This project shows how to fine-tune a GPT-2 model with LoRA adapters to create a lightweight storytelling agent.
It uses the TinyStories dataset for short story style and runs easily in Google Colab or on your local machine.

🚀 Features

✅ Fine-tune GPT-2 using LoRA (memory-efficient)

✅ Use TinyStories dataset for simple narrative style

✅ Save & reuse LoRA weights locally

✅ Easy to run inference with Gradio or Python script

✅ Perfect for creating a personalized StoryTeller chatbot




📦 Requirements


Python 3.10+


Packages:


transformers

datasets

peft

accelerate

bitsandbytes

gradio (for frontend, optional)


🏆 Credits

Dataset: TinyStories

Fine-Tuning: LoRA

Language Model: GPT-2





![Screenshot (840)](https://github.com/user-attachments/assets/908fa860-4982-42c6-9ad5-de6b52bb9f4e)


